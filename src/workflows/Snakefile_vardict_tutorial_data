# vim: syntax=python tabstop=4 expandtab
# vim: Limelight
# vim: let g:limelight_eop = '\"\n^'
# vim: let g:limelight_paragraph_span = 0 
# vim: let g:limelight_bop = '^rule'
# vim: let g:limelight_default_coefficient=1
# coding: utf-8

SAMPLES = ["tumor", "normal"]
ref_data_prefix="../../data/snakemake_tutorial_data_131217/"


rule final:
    input:
        ref_data_prefix + "output/calls/tumor_vs_normal.vcf",

rule get_data:
    output:
        expand(ref_data_prefix + "ref_data/samples/{sample}.fastq", sample=SAMPLES),
        ref_data_prefix + "ref_data/db/genome.fa"
    shell:
        "rm -rf {ref_data_prefix}ref_data; "
        "wget https://bitbucket.org/snakemake/snakemake/downloads/snakemake-tutorial-data.tar.gz; "
        "tar -xf snakemake-tutorial-data.tar.gz; "
        "rm requirements.txt; rm snakemake-tutorial-data.tar.gz; "
        "mv data {ref_data_prefix}ref_data; "
        "rm {ref_data_prefix}ref_data/genome.fa.*; "
        "mkdir -p {ref_data_prefix}ref_data/db; "
        "mv {ref_data_prefix}ref_data/genome.fa ../../data/snakemake_tutorial_data_131217/ref_data/db/; "
        "mv {ref_data_prefix}ref_data/samples/A.fastq ../../data/snakemake_tutorial_data_131217/ref_data/samples/tumor.fastq; "
        "mv {ref_data_prefix}ref_data/samples/B.fastq ../../data/snakemake_tutorial_data_131217/ref_data/samples/normal.fastq; "
        "rm {ref_data_prefix}ref_data/samples/C.fastq; "

rule ref_genome_index:
    input:
        fa=ref_data_prefix + "ref_data/db/genome.fa"
    output:
        expand(ref_data_prefix + "ref_data/db/genome.fa.{prefix}", prefix=["amb","ann","bwt","pac","sa"])
    shell:
        "bwa index {input.fa}; "
        "samtools faidx {input.fa}; "

rule bwa_map:
    input:
        fa=ref_data_prefix + "ref_data/db/genome.fa",
        fastq=ref_data_prefix + "ref_data/samples/{sample}.fastq",
        refidx=expand(ref_data_prefix + "ref_data/db/genome.fa.{prefix}", prefix=["amb","ann","bwt","pac","sa"])
    output:
        ref_data_prefix + "output/mapped_reads/{sample}.bam"
    log:
        ref_data_prefix + "output/logs/bwa_mem/{sample}.log"
    shell:
        "bwa mem {input.fa} {input.fastq} | samtools view -Sb - > {output} 2> {log}"

rule samtools_sort:
    input:
        bam=ref_data_prefix + "output/mapped_reads/{sample}.bam"
    output:
        ref_data_prefix + "output/mapped_reads/{sample}.sorted.bam"
    shell:
        "samtools sort -T {ref_data_prefix}output/mapped_reads/{wildcards.sample} "
        "-O bam {input.bam} > {output}"

rule remove_duplicate:
    input:
        bam=ref_data_prefix + "output/mapped_reads/{sample}.sorted.bam"
    output:
        bam=ref_data_prefix + "output/mapped_reads/{sample}.rmdup.bam"
    log:
        stats=ref_data_prefix + "output/logs/picard_stats/{sample}.rmdup.bam.txt"
    shell:
        "picard MarkDuplicates "
        "INPUT={input.bam} "
        "OUTPUT={output.bam} "
        "VALIDATION_STRINGENCY=SILENT "
        "MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=1000 "
        "REMOVE_DUPLICATES=TRUE "
        "METRICS_FILE='{log.stats}'"

rule samtools_index:
    input:
        ref_data_prefix + "output/mapped_reads/{sample}.rmdup.bam"
    output:
        ref_data_prefix + "output/mapped_reads/{sample}.rmdup.bam.bai"
    shell:
        "samtools index {input}"

rule samtools_merge:
    input:
        bam=expand(ref_data_prefix + "output/mapped_reads/{sample}.rmdup.bam", sample=SAMPLES)
    output:
        mergedbam=ref_data_prefix + "output/mapped_reads/merged.bam"
    shell:
        "samtools merge -f {output.mergedbam} {input.bam}"

rule vardict_varcall_prepare_bed:
    input:
        mergedbam=ref_data_prefix + "output/mapped_reads/merged.bam"
    output:
        bed=ref_data_prefix + "output/mapped_reads/merged.bed"
    shell:
        "samtools view {input.mergedbam} "
        " | awk -v OFS=\"\\t\" "
        "'$3==\"I\" {{if (c[$3]==0) {{c[$3]=1; min[$3]=$4; max[$3]=$4;}} "
        "if (min[$3]>$4) min[$3]=$4; if (max[$3]<$4) max[$3]=$4}}"
        "END{{for (x in min) print x,min[x],max[x]}}' > {output.bed}"

rule vardict_varcall_paired:
    input:
        fa=ref_data_prefix + "ref_data/db/genome.fa",
        bamN=expand(ref_data_prefix + "output/mapped_reads/{sample}.rmdup.bam", sample=SAMPLES[1]),
        bamT=expand(ref_data_prefix + "output/mapped_reads/{sample}.rmdup.bam", sample=SAMPLES[0]),
        bed=ref_data_prefix + "output/mapped_reads/merged.bed",
        bai=expand(ref_data_prefix + "output/mapped_reads/{sample}.rmdup.bam.bai", sample=SAMPLES)
    output:
        ref_data_prefix + "output/calls/tumor_vs_normal.vcf"
    shell:
        "vardict -G {input.fa} -f 0.01 -N TumorName "
        "-b \"{input.bamT}|{input.bamN}\" "
        "-c 1 -S 2 -E 3 -g 4 {input.bed} "
        "| testsomatic.R "
        "| var2vcf_paired.pl -N \"TumorName|NormalName\" -f 0.01 "
        "> {output}"

